{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":61944,"databundleVersionId":6757506,"sourceType":"competition"}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-30T10:28:07.976935Z","iopub.execute_input":"2024-06-30T10:28:07.977706Z","iopub.status.idle":"2024-06-30T10:28:07.990510Z","shell.execute_reply.started":"2024-06-30T10:28:07.977650Z","shell.execute_reply":"2024-06-30T10:28:07.989439Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install timm","metadata":{"execution":{"iopub.status.busy":"2024-06-30T10:28:07.992356Z","iopub.execute_input":"2024-06-30T10:28:07.992735Z","iopub.status.idle":"2024-06-30T10:28:20.567517Z","shell.execute_reply.started":"2024-06-30T10:28:07.992698Z","shell.execute_reply":"2024-06-30T10:28:20.566522Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.7)\nRequirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.10/site-packages (from timm) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.15.1)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.4)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.3.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (2023.9.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (4.66.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (21.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.23.5)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7->timm) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7->timm) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nfrom glob import glob\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport cv2\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\n\nfrom tqdm.notebook import tqdm\nimport albumentations as A\n\nimport timm\n\nDEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-06-30T10:28:20.568833Z","iopub.execute_input":"2024-06-30T10:28:20.569138Z","iopub.status.idle":"2024-06-30T10:28:27.160524Z","shell.execute_reply.started":"2024-06-30T10:28:20.569111Z","shell.execute_reply":"2024-06-30T10:28:27.159659Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/iitgai-ovha-23/train_labels.csv')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-30T10:28:27.161924Z","iopub.execute_input":"2024-06-30T10:28:27.162288Z","iopub.status.idle":"2024-06-30T10:28:27.202561Z","shell.execute_reply.started":"2024-06-30T10:28:27.162254Z","shell.execute_reply":"2024-06-30T10:28:27.201605Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                          image_name  \\\n0      medicakolkata_mau_mon--2_2022_6_8_6_8_51.jpeg   \n1  kamalnayanbajaj_micu_mon--22_2022_6_20_17_47_2...   \n2  kamalnayanbajaj_micu_mon--15_2022_6_20_22_46_2...   \n3   medicakolkata_ccu2_mon--3_2022_5_30_12_6_19.jpeg   \n4     medicakolkata_ccu2_mon--5_2022_6_8_6_6_37.jpeg   \n\n                                              points  \n0  [459.5, 169.5, 886.0999755859375, 172.19999694...  \n1  [422.4, 158, 967.8, 135.5, 957.3, 545.2, 409.5...  \n2  [497.4, 184.9, 792.7999877929688, 229.19999694...  \n3  [353.79998779296875, 112.69999694824219, 764.2...  \n4  [246.9, 155.3, 756.5999755859375, 205.89999389...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>points</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>medicakolkata_mau_mon--2_2022_6_8_6_8_51.jpeg</td>\n      <td>[459.5, 169.5, 886.0999755859375, 172.19999694...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>kamalnayanbajaj_micu_mon--22_2022_6_20_17_47_2...</td>\n      <td>[422.4, 158, 967.8, 135.5, 957.3, 545.2, 409.5...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>kamalnayanbajaj_micu_mon--15_2022_6_20_22_46_2...</td>\n      <td>[497.4, 184.9, 792.7999877929688, 229.19999694...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>medicakolkata_ccu2_mon--3_2022_5_30_12_6_19.jpeg</td>\n      <td>[353.79998779296875, 112.69999694824219, 764.2...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>medicakolkata_ccu2_mon--5_2022_6_8_6_6_37.jpeg</td>\n      <td>[246.9, 155.3, 756.5999755859375, 205.89999389...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def transform(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n    \"\"\"\n    Normalize an image tensor with the given mean and standard deviation.\n\n    Args:\n    - img (torch.Tensor): The image tensor to normalize, expected shape (C, H, W).\n    - mean (list): The mean values for each channel.\n    - std (list): The standard deviation values for each channel.\n\n    Returns:\n    - torch.Tensor: The normalized image tensor.\n    \"\"\"\n    # Convert the mean and std to tensors\n    mean = torch.tensor(mean).view(3, 1, 1)\n    std = torch.tensor(std).view(3, 1, 1)\n    \n    # Normalize the image\n    img = (img - mean) / std\n    \n    return img\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T10:28:27.204985Z","iopub.execute_input":"2024-06-30T10:28:27.205286Z","iopub.status.idle":"2024-06-30T10:28:27.211214Z","shell.execute_reply.started":"2024-06-30T10:28:27.205261Z","shell.execute_reply":"2024-06-30T10:28:27.210310Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import json\nclass NaturalDataset(Dataset):\n\n    # constructor\n    def __init__(self, train = True,transform=None):\n\n        super().__init__()\n        train_df=pd.read_csv('/kaggle/input/iitgai-ovha-23/train_labels.csv')\n        # initialize lists to store paths of images and their corresponding labels\n        self.image_paths = []\n        self.labels = []\n        image_dir='/kaggle/input/iitgai-ovha-23/images'\n        \n        for i in range(train_df.shape[0]):\n            self.image_paths.append(f\"{image_dir}/{train_df.image_name[i]}\")\n            string_representation=train_df.points[i]\n            extracted_list=json.loads(string_representation)\n            numpy_array=np.array(extracted_list)\n            self.labels.append(numpy_array)\n\n       \n        # train_test_split (random state has to be fixed to maintain the same split)\n        image_train, image_val, label_train, label_val = train_test_split(self.image_paths, self.labels, shuffle=True, test_size = 0.1, random_state=2000)\n\n        if train:\n            self.image_paths = image_train\n            self.labels = label_train\n            if transform is not None:\n                self.transform=transform\n        else:\n            self.image_paths = image_val\n            self.labels = label_val\n            if transform is not None:\n                self.transform=transform\n\n        # function for augumentation and preprocessing\n        \n\n\n    # len function\n    def __len__(self):\n        return len(self.image_paths)\n\n\n    # function to return the pair (image, label)\n    def __getitem__(self, idx):\n\n        # read image\n        img_path = self.image_paths[idx]\n        img = cv2.imread(img_path)\n        #img = img[:, :, ::-1]\n\n        \n\n        # making the required shape of the image\n        img = img.transpose(2, 0, 1)\n\n        # image tensor\n        img_tensor = torch.tensor(img, dtype=torch.float)\n        img_tensor=self.transform(img_tensor) ## normalization\n\n        # label tensor\n        label = self.labels[idx]\n        label_tensor = torch.tensor(label, dtype=torch.float)\n\n        return img_tensor, label_tensor","metadata":{"execution":{"iopub.status.busy":"2024-06-30T10:28:27.212700Z","iopub.execute_input":"2024-06-30T10:28:27.213088Z","iopub.status.idle":"2024-06-30T10:28:27.225692Z","shell.execute_reply.started":"2024-06-30T10:28:27.213056Z","shell.execute_reply":"2024-06-30T10:28:27.224794Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_dataset = NaturalDataset(train=True,transform=transform)\ntrain_loader = DataLoader(train_dataset,\n                          batch_size = 8,\n                          num_workers = 2,\n                          drop_last = True,\n                          shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T10:28:27.226900Z","iopub.execute_input":"2024-06-30T10:28:27.227150Z","iopub.status.idle":"2024-06-30T10:28:27.317831Z","shell.execute_reply.started":"2024-06-30T10:28:27.227128Z","shell.execute_reply":"2024-06-30T10:28:27.317009Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"val_dataset = NaturalDataset(train=False,transform=transform)\nval_loader = DataLoader(val_dataset,\n                          batch_size = 8,\n                          num_workers = 2,\n                          drop_last = False,\n                          shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T10:28:27.318849Z","iopub.execute_input":"2024-06-30T10:28:27.319126Z","iopub.status.idle":"2024-06-30T10:28:27.403978Z","shell.execute_reply.started":"2024-06-30T10:28:27.319103Z","shell.execute_reply":"2024-06-30T10:28:27.403219Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"pretrained_model = timm.create_model('resnet18', pretrained = True, num_classes = 0)\npretrained_model","metadata":{"execution":{"iopub.status.busy":"2024-06-30T10:28:27.405167Z","iopub.execute_input":"2024-06-30T10:28:27.405427Z","iopub.status.idle":"2024-06-30T10:28:28.438875Z","shell.execute_reply.started":"2024-06-30T10:28:27.405405Z","shell.execute_reply":"2024-06-30T10:28:28.437983Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/46.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90cab7b854424b48b5b00e95fb68befd"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act1): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n    )\n  )\n  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n  (fc): Identity()\n)"},"metadata":{}}]},{"cell_type":"code","source":"class CustomModel(nn.Module):\n\n    def __init__(self, num_classes = 8):\n        super().__init__()\n\n        # initialize backbone using pretrained model (hint: use num_classes = 0)\n        self.backbone = timm.create_model('resnet18', pretrained = True, num_classes = 0)\n\n        # 2 linear layers after the backbone\n        self.linear1 = nn.Linear(512,120)\n        self.linear2 = nn.Linear(120,8)\n        self.relu=nn.ReLU() \n        # softmax function\n        \n\n    def forward(self, x):\n        x = self.backbone(x)\n        \n\n        x = self.linear1(x)\n        \n        x=self.relu(x)\n        x = self.linear2(x)\n        \n\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-06-30T10:28:28.440067Z","iopub.execute_input":"2024-06-30T10:28:28.440350Z","iopub.status.idle":"2024-06-30T10:28:28.447072Z","shell.execute_reply.started":"2024-06-30T10:28:28.440325Z","shell.execute_reply":"2024-06-30T10:28:28.446162Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model=CustomModel()","metadata":{"execution":{"iopub.status.busy":"2024-06-30T10:28:28.448404Z","iopub.execute_input":"2024-06-30T10:28:28.448779Z","iopub.status.idle":"2024-06-30T10:28:28.696692Z","shell.execute_reply.started":"2024-06-30T10:28:28.448754Z","shell.execute_reply":"2024-06-30T10:28:28.695859Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model.to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T10:28:28.698091Z","iopub.execute_input":"2024-06-30T10:28:28.698653Z","iopub.status.idle":"2024-06-30T10:28:28.893137Z","shell.execute_reply.started":"2024-06-30T10:28:28.698615Z","shell.execute_reply":"2024-06-30T10:28:28.892243Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"CustomModel(\n  (backbone): ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n    )\n    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n    (fc): Identity()\n  )\n  (linear1): Linear(in_features=512, out_features=120, bias=True)\n  (linear2): Linear(in_features=120, out_features=8, bias=True)\n  (relu): ReLU()\n)"},"metadata":{}}]},{"cell_type":"code","source":"criterion=nn.MSELoss()\noptimizer=torch.optim.Adam(model.parameters(),lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T10:28:28.894524Z","iopub.execute_input":"2024-06-30T10:28:28.895208Z","iopub.status.idle":"2024-06-30T10:28:28.900429Z","shell.execute_reply.started":"2024-06-30T10:28:28.895160Z","shell.execute_reply":"2024-06-30T10:28:28.899463Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def train_fn(train_loader, model, criterion, optimizer):\n\n    # list to store the loss calculated on each batch\n    losses = []\n\n    # to enable batchnorm, dropout etc.\n    model.train()\n\n    progress = tqdm(train_loader, total=len(train_loader))\n\n    for i, (imgs, labels) in enumerate(progress):\n\n        # image and label tensors should be on the same device\n        imgs = imgs.to(DEVICE)\n        labels = labels.to(DEVICE)\n\n        # Forward Propogation and calculation of loss\n        y_preds = model(imgs)\n        loss = criterion(y_preds, labels)\n\n        # Back Propogation\n        optimizer.zero_grad()         # Clearing all previous gradients, setting them to zero\n        loss.backward()               # Calculating the new gradients (backprop)\n        optimizer.step()              # Updating the weights using the gradients\n\n        # appending the loss to the list\n        losses.append(loss.item())\n\n    # returning the mean loss overhe epoch\n    return  np.mean(losses)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T10:28:28.905137Z","iopub.execute_input":"2024-06-30T10:28:28.905510Z","iopub.status.idle":"2024-06-30T10:28:28.912825Z","shell.execute_reply.started":"2024-06-30T10:28:28.905467Z","shell.execute_reply":"2024-06-30T10:28:28.911953Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def val_fn(val_loader, model, criterion, optimizer):\n\n    # list to store the loss calculated on each batch\n    losses = []\n\n    # to disable batchnorm, dropout etc.\n    model.eval()\n\n    progress = tqdm(val_loader, total=len(val_loader))\n\n    for i, (imgs, labels) in enumerate(progress):\n\n        # image and label tensors should be on the same device as that of model\n        imgs = imgs.to(DEVICE)\n        labels = labels.to(DEVICE)\n\n        # to disable the calculation of gradients\n        with torch.no_grad():\n\n            # Forward Propogation and calculation of loss\n            y_preds = model(imgs)\n            loss = criterion(y_preds,labels)\n\n        # appending the loss to the list\n        losses.append(loss.item())\n\n    # returning the mean loss over the epoch\n    return np.mean(losses)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T10:28:28.913996Z","iopub.execute_input":"2024-06-30T10:28:28.914677Z","iopub.status.idle":"2024-06-30T10:28:28.921484Z","shell.execute_reply.started":"2024-06-30T10:28:28.914643Z","shell.execute_reply":"2024-06-30T10:28:28.920646Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 16\n\n# list to store the loss of each epoch\ntrain_losses = []\nval_losses = []\n\n# for storing the best weights of the model\nbest_dict = None\nbest_loss = np.inf\n\nfor ep in range(EPOCHS):\n\n    print('='*5 + f\" Epoch {ep+1} \" + '='*5)\n\n    # training and validation loop\n    tr_loss = train_fn(train_loader, model, criterion, optimizer)\n    val_loss = val_fn(val_loader, model, criterion, optimizer)\n\n    # updating the best weights, if loss is even less than the best one\n    if val_loss < best_loss:\n        best_loss = val_loss\n        best_dict = model.state_dict()\n\n    # appending the loss of each epoch\n    train_losses.append(tr_loss)\n    val_losses.append(val_loss)\n\n    print(f\"Epoch {ep} - Train Loss {tr_loss:.4f} - Val Loss {val_loss:.4f}\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-06-30T10:28:50.422178Z","iopub.execute_input":"2024-06-30T10:28:50.423159Z","iopub.status.idle":"2024-06-30T10:54:11.856524Z","shell.execute_reply.started":"2024-06-30T10:28:50.423122Z","shell.execute_reply":"2024-06-30T10:54:11.855529Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"===== Epoch 1 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fa131c9f9a74f899bb7859ebcf32668"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bf84a0c8a714ba9833c79c4f7800277"}},"metadata":{}},{"name":"stdout","text":"Epoch 0 - Train Loss 48586.5032 - Val Loss 7771.6541\n\n===== Epoch 2 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f10b4920b7d04673bf170757845a0b12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f6fa87824d045dcb2f59bc689269f25"}},"metadata":{}},{"name":"stdout","text":"Epoch 1 - Train Loss 5880.9881 - Val Loss 7041.9887\n\n===== Epoch 3 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"412633b5333d4eb0b6ddfcfe2dfe24c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4028935e2bdd421d87a3e81947d672f8"}},"metadata":{}},{"name":"stdout","text":"Epoch 2 - Train Loss 5207.1662 - Val Loss 7747.2444\n\n===== Epoch 4 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f77adea11244b549320cf324ac6120f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8dbe69552b44a1d85ea3d34404feb08"}},"metadata":{}},{"name":"stdout","text":"Epoch 3 - Train Loss 5079.9551 - Val Loss 4984.1504\n\n===== Epoch 5 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6b19a3a24a44dd89201d535fe08e663"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c7d2c20a43f45d7b6cda91703806c79"}},"metadata":{}},{"name":"stdout","text":"Epoch 4 - Train Loss 4857.4755 - Val Loss 4842.7600\n\n===== Epoch 6 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aea957ba6aa14a7199ac0a839d697aa9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"476fb45b6a8f48cbbf8629c38ed5274c"}},"metadata":{}},{"name":"stdout","text":"Epoch 5 - Train Loss 4665.8977 - Val Loss 4502.6253\n\n===== Epoch 7 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7e7535eddb04df29c27b41a338077d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d5aebd2d2734bf0918e0fb35157e9ad"}},"metadata":{}},{"name":"stdout","text":"Epoch 6 - Train Loss 4664.7560 - Val Loss 4930.2937\n\n===== Epoch 8 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68614e15044b498d9daa1e3a9e008fc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ce06370098e474190b6e213022cf17f"}},"metadata":{}},{"name":"stdout","text":"Epoch 7 - Train Loss 4637.3950 - Val Loss 9131.9352\n\n===== Epoch 9 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78fad2602d0f4f4b901591d7c76b083a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4947a9f3495448ec83ad1ee20c3f33e7"}},"metadata":{}},{"name":"stdout","text":"Epoch 8 - Train Loss 4608.4633 - Val Loss 5183.4906\n\n===== Epoch 10 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae1e5d2320a5469a8b8d5fd541be9a12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"726b4e2474d842e4afe179dba40e615c"}},"metadata":{}},{"name":"stdout","text":"Epoch 9 - Train Loss 4529.1113 - Val Loss 4885.4999\n\n===== Epoch 11 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"713ed22facb14504ad6dc6e785b3b7d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f20f3267aa64b999af87cf2825c3533"}},"metadata":{}},{"name":"stdout","text":"Epoch 10 - Train Loss 4547.8512 - Val Loss 4362.4202\n\n===== Epoch 12 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2201e842ae3a439db6e087f34a00584a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6425e8b800dc446a865190254a544213"}},"metadata":{}},{"name":"stdout","text":"Epoch 11 - Train Loss 4396.4766 - Val Loss 4502.7837\n\n===== Epoch 13 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f7dd0beb1a44ef1a051ae81875ed4e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4627a6ea38e44d84aa9c44510ffec9d3"}},"metadata":{}},{"name":"stdout","text":"Epoch 12 - Train Loss 4420.4234 - Val Loss 5001.9405\n\n===== Epoch 14 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7efce9149374a4db323fd0478de54b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9883dd66be834c84b6a13ad8e361891a"}},"metadata":{}},{"name":"stdout","text":"Epoch 13 - Train Loss 3769.8433 - Val Loss 3140.4742\n\n===== Epoch 15 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f2f4b24941246f98d6162d2e9487f06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83d9a331c253497d9586fa69105b3609"}},"metadata":{}},{"name":"stdout","text":"Epoch 14 - Train Loss 3017.3075 - Val Loss 2610.2836\n\n===== Epoch 16 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e604e49a17eb477baa0e18e718b622b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbd3b06594c54f63835d51a0ac3b3f40"}},"metadata":{}},{"name":"stdout","text":"Epoch 15 - Train Loss 2728.2325 - Val Loss 2618.9449\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_state_dict(best_dict)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T10:55:27.421592Z","iopub.execute_input":"2024-06-30T10:55:27.422467Z","iopub.status.idle":"2024-06-30T10:55:27.434015Z","shell.execute_reply.started":"2024-06-30T10:55:27.422432Z","shell.execute_reply":"2024-06-30T10:55:27.433035Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 30\n\n# list to store the loss of each epoch\ntrain_losses = []\nval_losses = []\n\n\nfor ep in range(EPOCHS):\n\n    print('='*5 + f\" Epoch {ep+1} \" + '='*5)\n\n    # training and validation loop\n    tr_loss = train_fn(train_loader, model, criterion, optimizer)\n    val_loss = val_fn(val_loader, model, criterion, optimizer)\n\n    # updating the best weights, if loss is even less than the best one\n    if val_loss < best_loss:\n        best_loss = val_loss\n        best_dict = model.state_dict()\n\n    # appending the loss of each epoch\n    train_losses.append(tr_loss)\n    val_losses.append(val_loss)\n\n    print(f\"Epoch {ep} - Train Loss {tr_loss:.4f} - Val Loss {val_loss:.4f}\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-06-30T11:00:34.446017Z","iopub.execute_input":"2024-06-30T11:00:34.446415Z","iopub.status.idle":"2024-06-30T11:48:16.582915Z","shell.execute_reply.started":"2024-06-30T11:00:34.446380Z","shell.execute_reply":"2024-06-30T11:48:16.581599Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"===== Epoch 1 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88bb8588667a41d3817bb11560c564ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f09395473e244e8b9e3a35946ec19f8e"}},"metadata":{}},{"name":"stdout","text":"Epoch 0 - Train Loss 1482.4029 - Val Loss 1387.3430\n\n===== Epoch 2 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e9299b23c1844cc8d2596dfe3db68f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52b2921b5c20428097bc7c4b8a8557a3"}},"metadata":{}},{"name":"stdout","text":"Epoch 1 - Train Loss 1116.4931 - Val Loss 1705.2185\n\n===== Epoch 3 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"883d31da23164be2a579cba6fc7ee6b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29a4d5f19c234c488a49f673347bc1ea"}},"metadata":{}},{"name":"stdout","text":"Epoch 2 - Train Loss 1034.5800 - Val Loss 918.7688\n\n===== Epoch 4 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24e9982e6cf34fdf85fc4e548884bab5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f53e082e6dd4fd2b714b08724a97962"}},"metadata":{}},{"name":"stdout","text":"Epoch 3 - Train Loss 832.1524 - Val Loss 707.0886\n\n===== Epoch 5 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b97a158e5e974a37afb0896afc682bfe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2463e6b9771f494cae82d45197c67a94"}},"metadata":{}},{"name":"stdout","text":"Epoch 4 - Train Loss 785.4365 - Val Loss 670.4312\n\n===== Epoch 6 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2009277fd76436680b328dcd791df8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"236a244eaa804b9db3ec7244d91c835e"}},"metadata":{}},{"name":"stdout","text":"Epoch 5 - Train Loss 739.0280 - Val Loss 625.0782\n\n===== Epoch 7 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17a74f064d77435cb1ca92fafadb6a8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"644a2b2daa2444b4ba84c0a21d39bc98"}},"metadata":{}},{"name":"stdout","text":"Epoch 6 - Train Loss 655.6213 - Val Loss 681.4640\n\n===== Epoch 8 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad7bb41533c44a7090b17aac7216bbe2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87a3a5c4a79545aaab005e3b66bac963"}},"metadata":{}},{"name":"stdout","text":"Epoch 7 - Train Loss 626.9033 - Val Loss 699.0172\n\n===== Epoch 9 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9acdd9bf2b74880b007745528b214b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbcd552f01114e798a6a9f487ac6ed1c"}},"metadata":{}},{"name":"stdout","text":"Epoch 8 - Train Loss 569.1989 - Val Loss 528.5659\n\n===== Epoch 10 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63dcfe868915464f940a91d6fbab1504"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25d8c6c335da416f805ac5868df1c1e3"}},"metadata":{}},{"name":"stdout","text":"Epoch 9 - Train Loss 493.0631 - Val Loss 618.1921\n\n===== Epoch 11 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cdf2db803c2477b881a2bcae071f909"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41e2ac318ac541c38416beb432dc47b2"}},"metadata":{}},{"name":"stdout","text":"Epoch 10 - Train Loss 503.0750 - Val Loss 489.7635\n\n===== Epoch 12 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c984874100b4dbf8f6ba3be56a293f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"853ce7d4b27a4082bc939267ca77df87"}},"metadata":{}},{"name":"stdout","text":"Epoch 11 - Train Loss 515.6013 - Val Loss 453.6163\n\n===== Epoch 13 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a2da94b85a84cbf8298707851bf2ac4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8e10bae92704149b7b27480b871f74b"}},"metadata":{}},{"name":"stdout","text":"Epoch 12 - Train Loss 460.0783 - Val Loss 471.8842\n\n===== Epoch 14 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d17fadd83ac4e698601f3ba38ae8ca2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6aedde3f1ab499e8c8d657d001ba314"}},"metadata":{}},{"name":"stdout","text":"Epoch 13 - Train Loss 435.3180 - Val Loss 757.6577\n\n===== Epoch 15 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"741a8202d78c432480f9cae2ab5e0767"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aca02122164e472c956e7e814953aa13"}},"metadata":{}},{"name":"stdout","text":"Epoch 14 - Train Loss 432.4058 - Val Loss 403.2828\n\n===== Epoch 16 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffdb1a5fe6c143de813d8e0f2c168f79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"029ab3a8b7ba4297aa88061f070ed1c0"}},"metadata":{}},{"name":"stdout","text":"Epoch 15 - Train Loss 433.1591 - Val Loss 457.3042\n\n===== Epoch 17 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f32ad638d9bf4c1e8d9e0b1239871e12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73ddadd0fce140939a6b571b5a9b05b9"}},"metadata":{}},{"name":"stdout","text":"Epoch 16 - Train Loss 407.0061 - Val Loss 440.7607\n\n===== Epoch 18 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fa559527de146169a1b7f4edccd40e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77de02c2e658450aa2ce684e946d1fbf"}},"metadata":{}},{"name":"stdout","text":"Epoch 17 - Train Loss 380.0994 - Val Loss 522.7774\n\n===== Epoch 19 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"126fb5e8755d4a75865c345db32136e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20bd6af75c4d4d5b973670dff623c371"}},"metadata":{}},{"name":"stdout","text":"Epoch 18 - Train Loss 389.7705 - Val Loss 529.6037\n\n===== Epoch 20 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"976e8f61905549b3ad1a30fbb8301ecb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2216985df1b74b5a9df8b60577ebb483"}},"metadata":{}},{"name":"stdout","text":"Epoch 19 - Train Loss 371.7403 - Val Loss 394.2905\n\n===== Epoch 21 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4e786359aee4effaeca0411eeb26162"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1509c2223666437f879b5e0cffa090aa"}},"metadata":{}},{"name":"stdout","text":"Epoch 20 - Train Loss 322.6523 - Val Loss 327.2622\n\n===== Epoch 22 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"067a4e5c15974a228d2f7b5d66772e33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"602d1b1c12c14a6285f4048e1ae40c64"}},"metadata":{}},{"name":"stdout","text":"Epoch 21 - Train Loss 333.6641 - Val Loss 395.2534\n\n===== Epoch 23 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d082070903c42fdb089291930090154"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bef012605a940c5b23fba72575e1503"}},"metadata":{}},{"name":"stdout","text":"Epoch 22 - Train Loss 342.2906 - Val Loss 403.6300\n\n===== Epoch 24 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"200f2d78e48f40a2bb4b5fec02bfb195"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1db5827772ab46bdb9e38c6728cbd34b"}},"metadata":{}},{"name":"stdout","text":"Epoch 23 - Train Loss 335.7852 - Val Loss 397.3395\n\n===== Epoch 25 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34cbeb66c81641908cbd0b68d8b816f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa87d7b207314c748ac92c2c988136f9"}},"metadata":{}},{"name":"stdout","text":"Epoch 24 - Train Loss 302.4992 - Val Loss 880.7609\n\n===== Epoch 26 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"824778dba8364b198724c8fcc3b639d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4c3d82a611d4b82bd41224c14e04080"}},"metadata":{}},{"name":"stdout","text":"Epoch 25 - Train Loss 304.6261 - Val Loss 309.3611\n\n===== Epoch 27 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aefb3ddd4a22409c87a57d165ad279af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfce92ea7e104ab5b56c6a85a127cb01"}},"metadata":{}},{"name":"stdout","text":"Epoch 26 - Train Loss 316.1926 - Val Loss 456.3503\n\n===== Epoch 28 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"943fe558e5e9468da03db9e0ec453d77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6622e780c64e4f26838ffa691e21a4b1"}},"metadata":{}},{"name":"stdout","text":"Epoch 27 - Train Loss 270.7913 - Val Loss 381.6514\n\n===== Epoch 29 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdc72a1788f04fee940db339b03d647d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8edcbfe82b347339f6dc82f8bff0632"}},"metadata":{}},{"name":"stdout","text":"Epoch 28 - Train Loss 257.0618 - Val Loss 455.3676\n\n===== Epoch 30 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/202 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6504b1b06d294b0aa6c50fb2e055d44a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a97ae0dbf6b54be9b9d0bfe1fd53acd1"}},"metadata":{}},{"name":"stdout","text":"Epoch 29 - Train Loss 259.3361 - Val Loss 275.9611\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_state_dict(best_dict)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T11:49:05.968631Z","iopub.execute_input":"2024-06-30T11:49:05.969405Z","iopub.status.idle":"2024-06-30T11:49:05.981867Z","shell.execute_reply.started":"2024-06-30T11:49:05.969372Z","shell.execute_reply":"2024-06-30T11:49:05.980914Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"# list to store predicted and the true labels\nval_preds = []\nval_trues = []\n\n# prediction on validation dataset\nprogress = tqdm(val_loader, total=len(val_loader))\n\n# to disable batchnorm, dropout etc.\nmodel.eval()\n\nfor i, (imgs, labels) in enumerate(progress):\n\n    # image and label tensors should be on the same device as that of model\n    imgs = imgs.to(DEVICE)\n    labels = labels.to(DEVICE)\n\n    # forward propogation\n    with torch.no_grad():\n        y_preds = model(imgs)\n\n   \n     \n\n    # appending the predicted and true labels to the corresponding lists\n    val_preds.extend(y_preds.tolist())\n    val_trues.extend(labels.cpu().numpy().tolist())","metadata":{"execution":{"iopub.status.busy":"2024-06-30T11:49:07.587105Z","iopub.execute_input":"2024-06-30T11:49:07.587507Z","iopub.status.idle":"2024-06-30T11:49:12.643931Z","shell.execute_reply.started":"2024-06-30T11:49:07.587460Z","shell.execute_reply":"2024-06-30T11:49:12.642879Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42df3e42975f442f902fe548b2dc49c7"}},"metadata":{}}]},{"cell_type":"code","source":"val_preds[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-30T11:49:12.646171Z","iopub.execute_input":"2024-06-30T11:49:12.646538Z","iopub.status.idle":"2024-06-30T11:49:12.653945Z","shell.execute_reply.started":"2024-06-30T11:49:12.646469Z","shell.execute_reply":"2024-06-30T11:49:12.653001Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"[478.0431823730469,\n 308.7445983886719,\n 726.567626953125,\n 299.4227600097656,\n 718.6004638671875,\n 501.7144470214844,\n 471.03802490234375,\n 514.103271484375]"},"metadata":{}}]},{"cell_type":"code","source":"val_trues[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-30T11:49:12.655172Z","iopub.execute_input":"2024-06-30T11:49:12.655484Z","iopub.status.idle":"2024-06-30T11:49:12.663395Z","shell.execute_reply.started":"2024-06-30T11:49:12.655459Z","shell.execute_reply":"2024-06-30T11:49:12.662529Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"[436.6000061035156,\n 309.8999938964844,\n 696.7999877929688,\n 302.1000061035156,\n 698.0,\n 501.1000061035156,\n 435.5,\n 516.2000122070312]"},"metadata":{}}]},{"cell_type":"code","source":"import json\nclass TestDataset(Dataset):\n\n    # constructor\n    def __init__(self, train = True):\n\n        super().__init__()\n        train_df=pd.read_csv('/kaggle/input/iitgai-ovha-23/sample_submission.csv')\n        # initialize lists to store paths of images and their corresponding labels\n        self.image_paths = []\n        self.labels = []\n        image_dir='/kaggle/input/iitgai-ovha-23/test_images'\n        \n        for i in range(train_df.shape[0]):\n            self.image_paths.append(f\"{image_dir}/{train_df.image_name[i]}\")\n            \n       \n        \n\n\n    # len function\n    def __len__(self):\n        return len(self.image_paths)\n\n\n    # function to return the pair (image, label)\n    def __getitem__(self, idx):\n\n        # read image\n        img_path = self.image_paths[idx]\n        img = cv2.imread(img_path)\n        #img = img[:, :, ::-1]\n\n        \n\n        # making the required shape of the image\n        img = img.transpose(2, 0, 1)\n\n        # image tensor\n        img_tensor = torch.tensor(img, dtype=torch.float)\n        \n        \n        \n\n        return img_tensor","metadata":{"execution":{"iopub.status.busy":"2024-06-30T10:28:45.208564Z","iopub.status.idle":"2024-06-30T10:28:45.208903Z","shell.execute_reply.started":"2024-06-30T10:28:45.208741Z","shell.execute_reply":"2024-06-30T10:28:45.208757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestDataset(train=True)\ntest_loader = DataLoader(test_dataset,\n                          batch_size = 8,\n                          num_workers = 2,\n                          drop_last = True,\n                          shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T10:28:45.210524Z","iopub.status.idle":"2024-06-30T10:28:45.210885Z","shell.execute_reply.started":"2024-06-30T10:28:45.210704Z","shell.execute_reply":"2024-06-30T10:28:45.210719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = []\n\n\n# prediction on validation dataset\nprogress = tqdm(test_loader, total=len(test_loader))\n\n# to disable batchnorm, dropout etc.\nmodel.eval()\n\nfor i, imgs in enumerate(progress):\n\n    # image and label tensors should be on the same device as that of model\n    imgs = imgs.to(DEVICE)\n    \n\n    # forward propogation\n    with torch.no_grad():\n        y_preds = model(imgs)\n\n   \n     \n\n    # appending the predicted and true labels to the corresponding lists\n    test_preds.extend(f'{y_preds.tolist()}')\n    ","metadata":{"execution":{"iopub.status.busy":"2024-06-30T10:28:45.212017Z","iopub.status.idle":"2024-06-30T10:28:45.212344Z","shell.execute_reply.started":"2024-06-30T10:28:45.212182Z","shell.execute_reply":"2024-06-30T10:28:45.212197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/iitgai-ovha-23/sample_submission.csv')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-30T10:28:45.213797Z","iopub.status.idle":"2024-06-30T10:28:45.214123Z","shell.execute_reply.started":"2024-06-30T10:28:45.213963Z","shell.execute_reply":"2024-06-30T10:28:45.213978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=data.drop(columns='points')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T10:28:45.215611Z","iopub.status.idle":"2024-06-30T10:28:45.215923Z","shell.execute_reply.started":"2024-06-30T10:28:45.215768Z","shell.execute_reply":"2024-06-30T10:28:45.215782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['points']=pd.Series(test_preds)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T10:28:45.218069Z","iopub.status.idle":"2024-06-30T10:28:45.218414Z","shell.execute_reply.started":"2024-06-30T10:28:45.218244Z","shell.execute_reply":"2024-06-30T10:28:45.218260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-30T10:28:45.219569Z","iopub.status.idle":"2024-06-30T10:28:45.219900Z","shell.execute_reply.started":"2024-06-30T10:28:45.219739Z","shell.execute_reply":"2024-06-30T10:28:45.219754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.to_csv('/kaggle/working/submission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-06-30T10:28:45.221296Z","iopub.status.idle":"2024-06-30T10:28:45.221638Z","shell.execute_reply.started":"2024-06-30T10:28:45.221450Z","shell.execute_reply":"2024-06-30T10:28:45.221465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}